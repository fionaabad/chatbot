import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import AIMessage, HumanMessage

# =========================
# Configuraci贸n inicial
# =========================
st.set_page_config(page_title="Chatbot B谩sico", page_icon="")
st.title(" Chatbot - con LangChain")
st.markdown("Este es un *chatbot de ejemplo* construido con LangChain + Streamlit.")

# =========================
# Tema pastel + burbujas de colores
# =========================
st.markdown(
    """
    <style>
    .stApp {
        background: linear-gradient(135deg, #e3f2fd 0%, #fce4ec 100%);
    }
    .user_msg {
        background-color: #bbdefb;
        border-radius: 15px;
        padding: 10px;
    }
    .ai_msg {
        background-color: #f8bbd0;
        border-radius: 15px;
        padding: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# =========================
# Men煤 lateral (configuraci贸n)
# =========================
st.sidebar.title("Configuraci贸n del modelo")

# -------- Estilo / temperatura con slider --------
opciones_estilo = [
    "Muy t茅cnica",
    "T茅cnica",
    "Equilibrada",
    "Creativa",
    "Muy creativa"
]

indice_personalidad = st.sidebar.slider(
    "Estilo de respuesta",
    min_value=0,
    max_value=len(opciones_estilo) - 1,
    value=2,  # Equilibrada por defecto
    step=1,
)

estilo_respuesta = opciones_estilo[indice_personalidad]

mapa_temperatura = {
    "Muy t茅cnica": 0.1,
    "T茅cnica": 0.3,
    "Equilibrada": 0.5,
    "Creativa": 0.7,
    "Muy creativa": 0.9,
}

temperatura = mapa_temperatura[estilo_respuesta]

st.sidebar.markdown(f" **Estilo actual:** {estilo_respuesta}")
st.sidebar.caption(f"Temperatura real: {temperatura}")

# -------- Selector de modelo --------
modelo_seleccionado = st.sidebar.selectbox(
    "Modelo",
    ["gemini-2.5-flash", "gemini-1.5-flash", "gemini-1.5-pro"],
)

# -------- Modo explicaci贸n paso a paso --------
modo_explicativo = st.sidebar.checkbox("Modo explicaci贸n paso a paso")

# -------- Personalidad del asistente --------
personalidad = st.sidebar.selectbox(
    "Personalidad",
    ["Normal", "Profesor paciente", "Comediante", "Experto formal", "Explica como si tuviera 5 a帽os"],
)

# -------- Bot贸n para limpiar conversaci贸n --------
if st.sidebar.button("Limpiar conversaci贸n"):
    st.session_state.mensajes = []

# Mostrar info arriba
st.caption(f"**Modelo activo:** {modelo_seleccionado} 路 **Estilo:** {estilo_respuesta} 路 **Personalidad:** {personalidad}")

# =========================
# Crear el modelo de chat con la config elegida
# =========================
chat_model = ChatGoogleGenerativeAI(
    model=modelo_seleccionado,
    temperature=temperatura,
)

# =========================
# Historial de mensajes
# =========================
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# Mostrar historial ya guardado con burbujas de colores
for msg in st.session_state.mensajes:
    role = "assistant" if isinstance(msg, AIMessage) else "user"
    css_class = "ai_msg" if role == "assistant" else "user_msg"
    with st.chat_message(role):
        st.markdown(f"<div class='{css_class}'>{msg.content}</div>", unsafe_allow_html=True)

# =========================
# Input del usuario
# =========================
pregunta = st.chat_input("Escribe tu mensaje:")

if pregunta:
    # Construir prefijo seg煤n personalidad y modo explicativo
    prefijo = ""

    if personalidad == "Profesor paciente":
        prefijo += "Responde de manera clara y pedag贸gica, como un profesor paciente. "
    elif personalidad == "Comediante":
        prefijo += "Responde con humor y chistes, pero sin dejar de ser 煤til. "
    elif personalidad == "Experto formal":
        prefijo += "Responde de manera muy formal y profesional. "
    elif personalidad == "Explica como si tuviera 5 a帽os":
        prefijo += "Expl铆calo con palabras muy sencillas, como a una ni帽a de 5 a帽os. "

    if modo_explicativo:
        prefijo += "Explica paso a paso y con mucho detalle. "

    contenido_para_modelo = prefijo + pregunta

    # Mostrar y guardar mensaje del usuario (solo el texto original, sin prefijos)
    with st.chat_message("user"):
        st.markdown(f"<div class='user_msg'>{pregunta}</div>", unsafe_allow_html=True)
    st.session_state.mensajes.append(HumanMessage(content=contenido_para_modelo))

    # Llamar al modelo con todo el historial
    respuesta = chat_model.invoke(st.session_state.mensajes)

    # Mostrar y guardar respuesta del asistente
    with st.chat_message("assistant"):
        st.markdown(f"<div class='ai_msg'>{respuesta.content}</div>", unsafe_allow_html=True)
    st.session_state.mensajes.append(respuesta)
